name: Manage NYC Events

on:
  schedule:
    # Run daily at midnight UTC
    - cron: '0 0 * * *'
  workflow_dispatch:  # Allow manual triggering

# Add permissions needed for the workflow
permissions:
  contents: write  # Give permission to push to the repository

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r scraper/requirements.txt
          
      - name: Run Scrapers and Generate Tweets
        run: |
          # Set PYTHONPATH and run the scraper
          export PYTHONPATH=$PYTHONPATH:$(pwd)
          echo "Running scraper with PYTHONPATH: $PYTHONPATH"
          
          # Create necessary directories
          mkdir -p scraper/data
          mkdir -p scraper/tech/data
          mkdir -p scraper/tech/tweets
          mkdir -p tech/tweets  # Create old directory for backward compatibility
          
          # Run the scraper module
          python -m scraper.tech.run_all
          
          # Generate tweets
          echo "Generating tweets"
          python -m scraper.tech.tweet_generator
          
          # Copy tweet files to the old location for backward compatibility
          echo "Copying tweet files to old location for backward compatibility"
          if [ -d "scraper/tech/tweets" ] && [ "$(ls -A scraper/tech/tweets)" ]; then
            cp -r scraper/tech/tweets/* tech/tweets/
          fi
          
      - name: Commit and Push Changes
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          # Add all relevant data files
          echo "Adding data files..."
          git add scraper/data/*.json
          git add scraper/tech/data/*.json
          
          # Add tweet files if they exist
          if ls scraper/tech/tweets/*.html 1> /dev/null 2>&1; then
            echo "Adding tweet files..."
            git add scraper/tech/tweets/*.html
          else
            echo "No tweet files found to add"
          fi
          
          # Add old tweet files location too
          if ls tech/tweets/*.html 1> /dev/null 2>&1; then
            echo "Adding old location tweet files..."
            git add tech/tweets/*.html
          fi
          
          if git diff --quiet && git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Update events data and tweets [skip ci]"
            git push
          fi
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          
      # Deploy to Vercel if configured
      - name: Deploy to Vercel
        if: success()
        run: |
          if [ -z "$VERCEL_TOKEN" ]; then
            echo "VERCEL_TOKEN is not set. Skipping Vercel deployment."
            exit 0
          fi
          
          echo "Installing and deploying to Vercel..."
          npx vercel --token="${VERCEL_TOKEN}" --prod --confirm
        env:
          VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }}
          VERCEL_PROJECT_ID: ${{ secrets.VERCEL_PROJECT_ID }}
          VERCEL_ORG_ID: ${{ secrets.VERCEL_ORG_ID }} 